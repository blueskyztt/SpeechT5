# SpeechT5

[SpeechT5](https://arxiv.org/abs/2110.07205) is a framework exploring encoder-decoder pre-training for self-supervised
speech/text representation learning.
Researchers from Microsoft Asia Research Institute and Microsoft Cloud Computing Platform Azure Speech Group
successively proposed SpeechT5. Unlike most other models, we can use SpeechT5 to perform multiple tasks.
SpeechT5 can implement speech-to-text, text-to-speech, and speech-to-speech.
Speech-to-speech is used to convert between different voices or to perform speech enhancement.
The model we will deploy speecht5_tts can only convert English input text into speech.

## 1. Create a new Notebook Server

Create a new Notebook Server on the Kubeflow on vSphere platform.

- You can create your own custom image or use an image published by us here:

  `projects.registry.vmware.com/models/notebook/hf-inference-deploy@sha256:8c5960ce436881f37336b12556d7a661ea20e4dbfe9ac193516cf384daa51c19`

- set 2 CPUs, 4GB memory for this Notebook Server.

## 2. Connect to the Notebook Server

Open a Terminal window. Pull the code of this project by running

`git clone https://github.com/blueskyztt/SpeechT5.git`



## 3. Download model

- (Option1) Download the model from https://huggingface.co/microsoft/speecht5_tts/tree/main and put all model
  files in `./speecht5` directory which under the current directory.

- (Option2) Alternatively, you can download the model with the script `Download_model.py`, an example is
  in `prepare.sh`. Note this script also does the work in Part4.2. If you excuted `bash prepare.sh`, you can skip the
  Part4.2 because Part4.2 is also finished by this script.

Finally, The directory structure is as follows:

```text
./speecht5
├── .gitattributes
├── README.md
├── added_tokens.json
├── config.json
├── preprocessor_config.json
├── pytorch_model.bin
├── special_tokens_map.json
├── spm_char.model
└── tokenizer_config.json
```

## 4. Preparation

### 4.1 Python requirements

Install the python packages necessary for the service, listed in `requirements.txt`.

```shell
pip install -r ./requirements.txt
```

### 4.2 hifigan

- (Option1) The model prediction requires `hifigan`. Due to unstable network, you need to download this folder manually.
  Download these files from https://huggingface.co/microsoft/speecht5_hifigan/tree/main （Download archives
  from https://github.com/nltk/nltk_data/tree/gh-pages/packages and put them in `hifigan` under
  the current directory.）

- (Option2) Alternatively, you can also do this part with the script `prepare.sh`, just with below command.

```shell
bash prepare.sh
```

In short, you get the following directories and files finally.

```text
hifigan
├── .gitattributes
├── README.md
├── config.json
└── pytorch_model.bin

```

Now, current directory should contain these files and directories:

```text
├── Download_model.py
├── client.py
├── create_mar.sh
├── handler.py
├── hifigan
├── prepare.sh
├── readme.md
├── requirements.txt
├── speecht5
└── start_ts.sh
```

## 5. Create TorchServe Model Archiver File

```shell
bash ./create_mar.sh
```

After waiting for a while, we got the mar file needed for the service. Then we can start our service.

## 6. Start TorchServe

Now you can start service with below command.

```shell
bash ./start_ts.sh
```

## 7. Test Service

Request the service in the terminal, execute

```shell
python ./client.py
```

When you see 'Successfully generated output_client.wav', indicating that the requested service is successful. In the
current directory, you can find the file `output_client.wav`. Open `output_client.wav` and you can hear the sound
generated by the model.





